{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw files to .csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the input files\n",
    "input_dir = 'transcript'\n",
    "\n",
    "def process_txt_file(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "        csv_writer = csv.writer(outfile)\n",
    "        \n",
    "        header = ['time', 'emotion_1', 'emotion_2', 'emotion_3', 'emotion_4', 'emotion_5','emotion_6','emotion_7']\n",
    "        csv_writer.writerow(header)\n",
    "        \n",
    "        for line in infile:\n",
    "            data = json.loads(line.strip())\n",
    "            row = [int(data['time'])] + [int(score) for score in data['scores']]\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "# Function to recursively process nested content\n",
    "def process_content(csv_writer, content):\n",
    "    if isinstance(content, list):\n",
    "        for item in content:\n",
    "            process_content(csv_writer, item)\n",
    "    elif isinstance(content, dict):\n",
    "        role = content.get('role', '')\n",
    "        content_text = ''\n",
    "        time = int(content.get('time', '0'))\n",
    "        user_id = content.get('user_id', '')\n",
    "        if 'content' in content:\n",
    "            content_data = content['content']\n",
    "            if isinstance(content_data, list):\n",
    "                for sub_item in content_data:\n",
    "                    if isinstance(sub_item, dict) and sub_item.get('type') == 'text':\n",
    "                        content_text = sub_item.get('text', '')\n",
    "            elif isinstance(content_data, str):\n",
    "                content_text = content_data\n",
    "        csv_writer.writerow([role, content_text, time, user_id])\n",
    "\n",
    "# Function to process .json files and convert them to CSV\n",
    "def process_json_file(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w', newline='') as outfile:\n",
    "        csv_writer = csv.writer(outfile)\n",
    "        \n",
    "        header = ['role', 'content', 'time', 'user_id']\n",
    "        csv_writer.writerow(header)\n",
    "        \n",
    "        data_list = json.load(infile)\n",
    "        \n",
    "        for item in data_list:\n",
    "            process_content(csv_writer, item)\n",
    "\n",
    "# Walk through all directories and files\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    for filename in files:\n",
    "        if filename.endswith('.txt'):\n",
    "            input_file = os.path.join(root, filename)\n",
    "            output_file = os.path.join(root, 'processed_' + filename.replace('.txt', '.csv'))\n",
    "            process_txt_file(input_file, output_file)\n",
    "        elif filename.endswith('.json'):\n",
    "            input_file = os.path.join(root, filename)\n",
    "            output_file = os.path.join(root, 'processed_' + filename.replace('.json', '.csv'))\n",
    "            process_json_file(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating avg emotion scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder: transcript\n",
      "Required CSV files not found in this folder.\n",
      "Processing folder: transcript/20240705_133046\n",
      "Found user data CSV: transcript/20240705_133046/processed_Emili_20240705_133046.csv\n",
      "Found raw scores CSV: transcript/20240705_133046/processed_Emili_raw_20240705_133046.csv\n",
      "Processed data saved to transcript/20240705_133046/scored_20240705.csv\n",
      "Processing folder: transcript/20240705_134402\n",
      "Found user data CSV: transcript/20240705_134402/processed_Emili_20240705_134402.csv\n",
      "Found raw scores CSV: transcript/20240705_134402/processed_Emili_raw_20240705_134402.csv\n",
      "Processed data saved to transcript/20240705_134402/scored_20240705.csv\n",
      "Processing folder: transcript/20240702_154302\n",
      "Found user data CSV: transcript/20240702_154302/processed_Emili_20240702_154302.csv\n",
      "Found raw scores CSV: transcript/20240702_154302/processed_Emili_raw_20240702_154302.csv\n",
      "Processed data saved to transcript/20240702_154302/scored_20240702.csv\n",
      "Processing folder: transcript/20240705_124936\n",
      "Found user data CSV: transcript/20240705_124936/processed_Emili_20240705_124936.csv\n",
      "Found raw scores CSV: transcript/20240705_124936/processed_Emili_raw_20240705_124936.csv\n",
      "Processed data saved to transcript/20240705_124936/scored_20240705.csv\n"
     ]
    }
   ],
   "source": [
    "# Function to read CSV file into a list of dictionaries\n",
    "def read_csv_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r', newline='') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            data.append(row)\n",
    "    return data\n",
    "\n",
    "# Function to write data to a new CSV file\n",
    "def write_csv_file(file_path, header, data):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(header)\n",
    "        for row in data:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Function to generate random alphanumeric ID of given length\n",
    "def generate_random_id(length):\n",
    "    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))\n",
    "\n",
    "# Function to calculate average scores for a given time range\n",
    "def calculate_average_scores(raw_scores, target_time, role, time_window):\n",
    "    num_emotions = 7\n",
    "    sum_scores = [0] * num_emotions\n",
    "    count = 0\n",
    "\n",
    "    for score_data in raw_scores:\n",
    "        score_time = int(score_data['time'])\n",
    "\n",
    "        if role == 'user':\n",
    "            if target_time - time_window <= score_time <= target_time + time_window:\n",
    "                for i in range(num_emotions):\n",
    "                    sum_scores[i] += int(score_data[f'emotion_{i+1}'])\n",
    "                count += 1\n",
    "        elif role == 'assistant':\n",
    "            if target_time <= score_time <= target_time + time_window:\n",
    "                for i in range(num_emotions):\n",
    "                    sum_scores[i] += int(score_data[f'emotion_{i+1}'])\n",
    "                count += 1\n",
    "    \n",
    "    if count > 0:\n",
    "        avg_scores = [round(sum_score / count, 2) for sum_score in sum_scores]\n",
    "    else:\n",
    "        avg_scores = [0] * num_emotions\n",
    "    \n",
    "    return avg_scores\n",
    "\n",
    "# Function to process each folder and its files\n",
    "def process_folder(root):\n",
    "    print(f\"Processing folder: {root}\")\n",
    "    user_data_csv = None\n",
    "    raw_scores_csv = None\n",
    "    output_csv = None\n",
    "\n",
    "    used_ids = set()  # Set to store used conv_ids\n",
    "\n",
    "    for filename in os.listdir(root):\n",
    "        if filename.startswith('processed_Emili_') and filename.endswith('.csv') and not filename.endswith('_condensed.csv'):\n",
    "            if filename.startswith('processed_Emili_raw_'):\n",
    "                raw_scores_csv = os.path.join(root, filename)\n",
    "            else:\n",
    "                user_data_csv = os.path.join(root, filename)\n",
    "\n",
    "    if user_data_csv and raw_scores_csv:\n",
    "        timestamp = os.path.basename(user_data_csv).split('_')[2]\n",
    "        output_csv = os.path.join(root, f'scored_{timestamp}.csv')\n",
    "        print(f\"Found user data CSV: {user_data_csv}\")\n",
    "        print(f\"Found raw scores CSV: {raw_scores_csv}\")\n",
    "        user_data = read_csv_file(user_data_csv)\n",
    "        raw_scores_data = read_csv_file(raw_scores_csv)\n",
    "\n",
    "        output_header = ['Conv_id','time', 'role','user_id','content','Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "        output_data = []\n",
    "\n",
    "        # Generate unique conv_id\n",
    "        conv_id = generate_random_id(7)\n",
    "        while conv_id in used_ids:\n",
    "            conv_id = generate_random_id(7)\n",
    "        used_ids.add(conv_id)\n",
    "\n",
    "        for user_row in user_data:\n",
    "            if user_row['role'] == 'user':\n",
    "                time_window = 5\n",
    "                target_time = int(user_row['time'])\n",
    "                avg_scores = calculate_average_scores(raw_scores_data, target_time, user_row['role'], time_window)\n",
    "                output_row = [conv_id,user_row['time'],user_row['role'], user_row['user_id'], user_row['content']] + avg_scores\n",
    "                output_data.append(output_row)\n",
    "            elif user_row['role'] == 'assistant':\n",
    "                time_window = 10\n",
    "                target_time = int(user_row['time'])\n",
    "                avg_scores = calculate_average_scores(raw_scores_data, target_time, user_row['role'], time_window)\n",
    "                output_row = [conv_id,user_row['time'],user_row['role'], user_row['user_id'], user_row['content']] + avg_scores\n",
    "                output_data.append(output_row)\n",
    "            elif user_row['role'] == 'system':\n",
    "                output_row = [conv_id,user_row['time'],user_row['role'], user_row['user_id'], user_row['content']] + [0] * 7\n",
    "                output_data.append(output_row)\n",
    "        write_csv_file(output_csv, output_header, output_data)\n",
    "        print(f\"Processed data saved to {output_csv}\")\n",
    "    else:\n",
    "        print(\"Required CSV files not found in this folder.\")\n",
    "\n",
    "# Walk through all directories and process files\n",
    "input_dir = 'transcript'\n",
    "for root, dirs, files in os.walk(input_dir):\n",
    "    process_folder(root)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Temporal Difference and the flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: transcript/20240705_133046/scored_20240705.csv\n",
      "Processed data saved to transcript/20240705_133046/flagged_20240705.csv\n",
      "Processing file: transcript/20240705_134402/scored_20240705.csv\n",
      "Processed data saved to transcript/20240705_134402/flagged_20240705.csv\n",
      "Processing file: transcript/20240702_154302/scored_20240702.csv\n",
      "Processed data saved to transcript/20240702_154302/flagged_20240702.csv\n",
      "Processing file: transcript/20240705_124936/scored_20240705.csv\n",
      "Processed data saved to transcript/20240705_124936/flagged_20240705.csv\n",
      "Processing complete for all directories.\n"
     ]
    }
   ],
   "source": [
    "def process_scored_files_in_directory(directory):\n",
    "    # Iterate through files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith('scored_') and filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            print(f\"Processing file: {file_path}\")\n",
    "            \n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Compute tot_emo_score\n",
    "            df['tot_emo_score'] = df['Happy'] * 5 + df['Neutral'] * 1 - df['Sad'] * 2 + df['Surprise'] * 1 - df['Anger'] * 2 - df['Fear'] * 2 - df['Disgust'] * 5\n",
    "            \n",
    "            # Initialize flag column with NaNs\n",
    "            df['flag'] = np.nan\n",
    "            \n",
    "            # Explicitly cast flag column to boolean\n",
    "            df['flag'] = df['flag'].astype('object')\n",
    "            \n",
    "            # Iterate through each row with role 'assistant'\n",
    "            for idx, row in df.iterrows():\n",
    "                if row['role'] == 'assistant':\n",
    "                    # Search backwards to find the previous row with role 'user'\n",
    "                    prev_user_idx = idx - 1\n",
    "                    while prev_user_idx >= 0 and df.iloc[prev_user_idx]['role'] != 'user':\n",
    "                        prev_user_idx -= 1\n",
    "                    \n",
    "                    # Check if a valid previous 'user' row was found\n",
    "                    if prev_user_idx >= 0 and df.iloc[prev_user_idx]['role'] == 'user':\n",
    "                        if row['tot_emo_score'] - df.iloc[prev_user_idx]['tot_emo_score'] >= 0:\n",
    "                            df.at[idx, 'flag'] = True\n",
    "                        else:\n",
    "                            df.at[idx, 'flag'] = False\n",
    "            \n",
    "            # Extract file timestamp from filename\n",
    "            timestamp = filename.split('_')[1].split('.')[0]  # Adjust this based on your filename pattern\n",
    "            \n",
    "            # Save the modified DataFrame to a new CSV file\n",
    "            output_filename = f'flagged_{timestamp}.csv'\n",
    "            output_path = os.path.join(directory, output_filename)\n",
    "            df.to_csv(output_path, index=False)\n",
    "            \n",
    "            print(f\"Processed data saved to {output_path}\")\n",
    "\n",
    "# Define the main directory to process\n",
    "main_directory = 'transcript'\n",
    "\n",
    "# Iterate through each directory in the main directory\n",
    "for root, dirs, files in os.walk(main_directory):\n",
    "    for directory in dirs:\n",
    "        directory_path = os.path.join(root, directory)\n",
    "        process_scored_files_in_directory(directory_path)\n",
    "\n",
    "print(\"Processing complete for all directories.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV to JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_file(csv_file_path, messages):\n",
    "    with open(csv_file_path, 'r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        system_message = \"\"\n",
    "\n",
    "        for row in csv_reader:\n",
    "            id = ''\n",
    "\n",
    "            if row[\"role\"] == \"user\":\n",
    "                id = f\"user_id: {row['user_id']}. \"\n",
    "            # Process the content without the column name\n",
    "            content = id + row[\"content\"].replace('\\n', ' ').replace('\\r', ' ').strip()\n",
    "\n",
    "            if row[\"role\"] == \"system\":\n",
    "                system_message += content + \" \"\n",
    "                continue\n",
    "\n",
    "            if system_message:\n",
    "                messages.append({\"role\": \"system\", \"content\": system_message.strip()})\n",
    "                system_message = \"\"\n",
    "\n",
    "            message = {\n",
    "                \"role\": row[\"role\"],\n",
    "                \"content\": content\n",
    "            }\n",
    "            if row[\"role\"] == \"assistant\":\n",
    "                message[\"weight\"] = 1 if row[\"flag\"].lower() == \"true\" else 0\n",
    "\n",
    "            messages.append(message)\n",
    "\n",
    "        if system_message:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_message.strip()})\n",
    "\n",
    "\n",
    "def csv_to_jsonl(input_dir, jsonl_file_path):\n",
    "    messages = []\n",
    "\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for filename in files:\n",
    "            if filename.startswith('flagged_') and filename.endswith('.csv') and not filename.endswith('_condensed.csv'):\n",
    "                csv_file_path = os.path.join(root, filename)\n",
    "                process_csv_file(csv_file_path, messages)\n",
    "\n",
    "    with open(jsonl_file_path, 'w') as jsonl_file:\n",
    "        jsonl_file.write(json.dumps({\"messages\": messages}) + '\\n')\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_dir = 'test_script'  # Replace with the path to your directory\n",
    "    jsonl_file_path = 'Dataset_1.jsonl'  # Replace with the desired output JSONL file path\n",
    "    csv_to_jsonl(input_dir, jsonl_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
